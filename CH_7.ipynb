{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CH#7",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPiGr14G5+JzEw2eXPGJZc4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bilal444hammas/Piaic-Quarter-3/blob/master/CH_7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "taiWOQJC7Xm7",
        "colab_type": "text"
      },
      "source": [
        "### CH#7"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UjfQw8eI8KgD",
        "colab_type": "text"
      },
      "source": [
        "**Introduction to the functional API**\n",
        "                                                                                In the functional API , you directly manipulate tensors, and you use layers as functions\n",
        "that take tensors and return tensors (hence, the name functional API ):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1evFEPEn7VZL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import Input, layers\n",
        "input_tensor = Input(shape=(32,))\n",
        "dense = layers.Dense(32, activation='relu')\n",
        "output_tensor = dense(input_tensor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gxLCYMRg9L5a",
        "colab_type": "text"
      },
      "source": [
        "Letâ€™s start with a minimal example that shows side by side a simple Sequential model\n",
        "and its equivalent in the functional API :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07QHBcJw7Ujs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "c6d9450e-8bee-417a-c2c7-749b9161dd7b"
      },
      "source": [
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Input\n",
        "######(Sequential model, which you already know about)######\n",
        "seq_model = Sequential()\n",
        "seq_model.add(layers.Dense(32, activation='relu', input_shape=(64,)))\n",
        "seq_model.add(layers.Dense(32, activation='relu'))\n",
        "seq_model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "seq_model.summary()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 32)                1056      \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                330       \n",
            "=================================================================\n",
            "Total params: 3,466\n",
            "Trainable params: 3,466\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-m0ixNx94xu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "8805b717-fa17-48a7-8d4b-70caad192fbe"
      },
      "source": [
        "#### Its functional API or equivalent  ###\n",
        "input_tensor = Input(shape=(64,))\n",
        "x = layers.Dense(32, activation='relu')(input_tensor)\n",
        "x = layers.Dense(32, activation='relu')(x)\n",
        "output_tensor = layers.Dense(10, activation='softmax')(x)\n",
        "### The Model class turns an input tensor and output tensor into a model. ###\n",
        "model = Model(input_tensor, output_tensor)\n",
        "\n",
        "model.summary()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 64)]              0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 32)                1056      \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 10)                330       \n",
            "=================================================================\n",
            "Total params: 3,466\n",
            "Trainable params: 3,466\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGCItLAfnkK5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "outputId": "555befd7-cf40-4bb9-970d-25f3ee5cf5c4"
      },
      "source": [
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "\n",
        "SVG(model_to_dot(model,show_shapes=True).create(prog='dot', format='svg'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.SVG object>"
            ],
            "image/svg+xml": "<svg height=\"405pt\" viewBox=\"0.00 0.00 262.00 304.00\" width=\"349pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g class=\"graph\" id=\"graph0\" transform=\"scale(1.3333 1.3333) rotate(0) translate(4 300)\">\n<title>G</title>\n<polygon fill=\"#ffffff\" points=\"-4,4 -4,-300 258,-300 258,4 -4,4\" stroke=\"transparent\"/>\n<!-- 140139136660424 -->\n<g class=\"node\" id=\"node1\">\n<title>140139136660424</title>\n<polygon fill=\"none\" points=\"0,-249.5 0,-295.5 254,-295.5 254,-249.5 0,-249.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"66.5\" y=\"-268.8\">input_2: InputLayer</text>\n<polyline fill=\"none\" points=\"133,-249.5 133,-295.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"162\" y=\"-280.3\">input:</text>\n<polyline fill=\"none\" points=\"133,-272.5 191,-272.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"162\" y=\"-257.3\">output:</text>\n<polyline fill=\"none\" points=\"191,-249.5 191,-295.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"222.5\" y=\"-280.3\">[(?, 64)]</text>\n<polyline fill=\"none\" points=\"191,-272.5 254,-272.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"222.5\" y=\"-257.3\">[(?, 64)]</text>\n</g>\n<!-- 140139136662944 -->\n<g class=\"node\" id=\"node2\">\n<title>140139136662944</title>\n<polygon fill=\"none\" points=\"17.5,-166.5 17.5,-212.5 236.5,-212.5 236.5,-166.5 17.5,-166.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"71\" y=\"-185.8\">dense_4: Dense</text>\n<polyline fill=\"none\" points=\"124.5,-166.5 124.5,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"153.5\" y=\"-197.3\">input:</text>\n<polyline fill=\"none\" points=\"124.5,-189.5 182.5,-189.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"153.5\" y=\"-174.3\">output:</text>\n<polyline fill=\"none\" points=\"182.5,-166.5 182.5,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"209.5\" y=\"-197.3\">(?, 64)</text>\n<polyline fill=\"none\" points=\"182.5,-189.5 236.5,-189.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"209.5\" y=\"-174.3\">(?, 32)</text>\n</g>\n<!-- 140139136660424&#45;&gt;140139136662944 -->\n<g class=\"edge\" id=\"edge1\">\n<title>140139136660424-&gt;140139136662944</title>\n<path d=\"M127,-249.3799C127,-241.1745 127,-231.7679 127,-222.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"130.5001,-222.784 127,-212.784 123.5001,-222.784 130.5001,-222.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140139136662720 -->\n<g class=\"node\" id=\"node3\">\n<title>140139136662720</title>\n<polygon fill=\"none\" points=\"17.5,-83.5 17.5,-129.5 236.5,-129.5 236.5,-83.5 17.5,-83.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"71\" y=\"-102.8\">dense_5: Dense</text>\n<polyline fill=\"none\" points=\"124.5,-83.5 124.5,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"153.5\" y=\"-114.3\">input:</text>\n<polyline fill=\"none\" points=\"124.5,-106.5 182.5,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"153.5\" y=\"-91.3\">output:</text>\n<polyline fill=\"none\" points=\"182.5,-83.5 182.5,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"209.5\" y=\"-114.3\">(?, 32)</text>\n<polyline fill=\"none\" points=\"182.5,-106.5 236.5,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"209.5\" y=\"-91.3\">(?, 32)</text>\n</g>\n<!-- 140139136662944&#45;&gt;140139136662720 -->\n<g class=\"edge\" id=\"edge2\">\n<title>140139136662944-&gt;140139136662720</title>\n<path d=\"M127,-166.3799C127,-158.1745 127,-148.7679 127,-139.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"130.5001,-139.784 127,-129.784 123.5001,-139.784 130.5001,-139.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140139039000616 -->\n<g class=\"node\" id=\"node4\">\n<title>140139039000616</title>\n<polygon fill=\"none\" points=\"17.5,-.5 17.5,-46.5 236.5,-46.5 236.5,-.5 17.5,-.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"71\" y=\"-19.8\">dense_6: Dense</text>\n<polyline fill=\"none\" points=\"124.5,-.5 124.5,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"153.5\" y=\"-31.3\">input:</text>\n<polyline fill=\"none\" points=\"124.5,-23.5 182.5,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"153.5\" y=\"-8.3\">output:</text>\n<polyline fill=\"none\" points=\"182.5,-.5 182.5,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"209.5\" y=\"-31.3\">(?, 32)</text>\n<polyline fill=\"none\" points=\"182.5,-23.5 236.5,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"209.5\" y=\"-8.3\">(?, 10)</text>\n</g>\n<!-- 140139136662720&#45;&gt;140139039000616 -->\n<g class=\"edge\" id=\"edge3\">\n<title>140139136662720-&gt;140139039000616</title>\n<path d=\"M127,-83.3799C127,-75.1745 127,-65.7679 127,-56.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"130.5001,-56.784 127,-46.784 123.5001,-56.784 130.5001,-56.784\" stroke=\"#000000\"/>\n</g>\n</g>\n</svg>"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_z6uqNyW-oNh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "outputId": "2c99a70d-8759-482a-92c0-98d637fda4e7"
      },
      "source": [
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
        "### Generates dummy Numpy data to train on ##\n",
        "import numpy as np \n",
        "x_train = np.random.random((1000, 64))\n",
        "y_train = np.random.random((1000, 10))\n",
        "\n",
        "model.fit(x_train, y_train, epochs=10, batch_size=128)\n",
        "score = model.evaluate(x_train, y_train)\n",
        "print(score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 11.8813\n",
            "Epoch 2/10\n",
            "8/8 [==============================] - 0s 1ms/step - loss: 12.4218\n",
            "Epoch 3/10\n",
            "8/8 [==============================] - 0s 1ms/step - loss: 13.8708\n",
            "Epoch 4/10\n",
            "8/8 [==============================] - 0s 1ms/step - loss: 15.5743\n",
            "Epoch 5/10\n",
            "8/8 [==============================] - 0s 1ms/step - loss: 17.1785\n",
            "Epoch 6/10\n",
            "8/8 [==============================] - 0s 1ms/step - loss: 18.9981\n",
            "Epoch 7/10\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 21.2647\n",
            "Epoch 8/10\n",
            "8/8 [==============================] - 0s 1ms/step - loss: 23.4496\n",
            "Epoch 9/10\n",
            "8/8 [==============================] - 0s 1ms/step - loss: 26.0065\n",
            "Epoch 10/10\n",
            "8/8 [==============================] - 0s 1ms/step - loss: 28.6343\n",
            "32/32 [==============================] - 0s 812us/step - loss: 30.1570\n",
            "30.156980514526367\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kieYsGdkC1aw",
        "colab_type": "text"
      },
      "source": [
        "Listing 7.1 Functional API implementation of a two-input question-answering model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7LDuaDRnAKLF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Input\n",
        "text_vocabulary_size = 10000\n",
        "question_vocabulary_size = 10000\n",
        "answer_vocabulary_size = 500\n",
        "\n",
        "text_input = Input(shape=(None,), dtype='int32', name='text')\n",
        "embedded_text = layers.Embedding(text_vocabulary_size,64)(text_input)\n",
        "encoded_text = layers.LSTM(32)(embedded_text)\n",
        "\n",
        "question_input = Input(shape=(None,),dtype='int32',name='question')\n",
        "embedded_question = layers.Embedding( question_vocabulary_size,32)(question_input)\n",
        "encoded_question = layers.LSTM(16)(embedded_question)\n",
        "\n",
        "concatenated = layers.concatenate([encoded_text, encoded_question],axis=-1)\n",
        "\n",
        "answer = layers.Dense(answer_vocabulary_size,activation='softmax')(concatenated)\n",
        "\n",
        "model = Model([text_input, question_input], answer)\n",
        "model.compile(optimizer='rmsprop',\n",
        "loss='categorical_crossentropy',\n",
        "metrics=['acc'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MTEu8Y5GnkO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "outputId": "424e4400-a151-4ee9-ecd6-1643a50f9851"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "text (InputLayer)               [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "question (InputLayer)           [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, None, 64)     640000      text[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, None, 32)     320000      question[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 32)           12416       embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   (None, 16)           3136        embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 48)           0           lstm[0][0]                       \n",
            "                                                                 lstm_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_7 (Dense)                 (None, 500)          24500       concatenate[0][0]                \n",
            "==================================================================================================\n",
            "Total params: 1,000,052\n",
            "Trainable params: 1,000,052\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t62TglyFo6R6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 709
        },
        "outputId": "8fb187b4-a4c3-4434-c32a-750af1c237bf"
      },
      "source": [
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "\n",
        "SVG(model_to_dot(model,show_shapes=True).create(prog='dot', format='svg'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.SVG object>"
            ],
            "image/svg+xml": "<svg height=\"516pt\" viewBox=\"0.00 0.00 605.50 387.00\" width=\"807pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g class=\"graph\" id=\"graph0\" transform=\"scale(1.3333 1.3333) rotate(0) translate(4 383)\">\n<title>G</title>\n<polygon fill=\"#ffffff\" points=\"-4,4 -4,-383 601.5,-383 601.5,4 -4,4\" stroke=\"transparent\"/>\n<!-- 140139029415752 -->\n<g class=\"node\" id=\"node1\">\n<title>140139029415752</title>\n<polygon fill=\"none\" points=\"30.5,-332.5 30.5,-378.5 251.5,-378.5 251.5,-332.5 30.5,-332.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"85\" y=\"-351.8\">text: InputLayer</text>\n<polyline fill=\"none\" points=\"139.5,-332.5 139.5,-378.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"168.5\" y=\"-363.3\">input:</text>\n<polyline fill=\"none\" points=\"139.5,-355.5 197.5,-355.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"168.5\" y=\"-340.3\">output:</text>\n<polyline fill=\"none\" points=\"197.5,-332.5 197.5,-378.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"224.5\" y=\"-363.3\">[(?, ?)]</text>\n<polyline fill=\"none\" points=\"197.5,-355.5 251.5,-355.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"224.5\" y=\"-340.3\">[(?, ?)]</text>\n</g>\n<!-- 140139028904032 -->\n<g class=\"node\" id=\"node3\">\n<title>140139028904032</title>\n<polygon fill=\"none\" points=\"0,-249.5 0,-295.5 282,-295.5 282,-249.5 0,-249.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"78\" y=\"-268.8\">embedding: Embedding</text>\n<polyline fill=\"none\" points=\"156,-249.5 156,-295.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"185\" y=\"-280.3\">input:</text>\n<polyline fill=\"none\" points=\"156,-272.5 214,-272.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"185\" y=\"-257.3\">output:</text>\n<polyline fill=\"none\" points=\"214,-249.5 214,-295.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"248\" y=\"-280.3\">(?, ?)</text>\n<polyline fill=\"none\" points=\"214,-272.5 282,-272.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"248\" y=\"-257.3\">(?, ?, 64)</text>\n</g>\n<!-- 140139029415752&#45;&gt;140139028904032 -->\n<g class=\"edge\" id=\"edge1\">\n<title>140139029415752-&gt;140139028904032</title>\n<path d=\"M141,-332.3799C141,-324.1745 141,-314.7679 141,-305.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"144.5001,-305.784 141,-295.784 137.5001,-305.784 144.5001,-305.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140138997141576 -->\n<g class=\"node\" id=\"node2\">\n<title>140138997141576</title>\n<polygon fill=\"none\" points=\"324.5,-332.5 324.5,-378.5 573.5,-378.5 573.5,-332.5 324.5,-332.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"393\" y=\"-351.8\">question: InputLayer</text>\n<polyline fill=\"none\" points=\"461.5,-332.5 461.5,-378.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"490.5\" y=\"-363.3\">input:</text>\n<polyline fill=\"none\" points=\"461.5,-355.5 519.5,-355.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"490.5\" y=\"-340.3\">output:</text>\n<polyline fill=\"none\" points=\"519.5,-332.5 519.5,-378.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"546.5\" y=\"-363.3\">[(?, ?)]</text>\n<polyline fill=\"none\" points=\"519.5,-355.5 573.5,-355.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"546.5\" y=\"-340.3\">[(?, ?)]</text>\n</g>\n<!-- 140140041180552 -->\n<g class=\"node\" id=\"node4\">\n<title>140140041180552</title>\n<polygon fill=\"none\" points=\"300.5,-249.5 300.5,-295.5 597.5,-295.5 597.5,-249.5 300.5,-249.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"386\" y=\"-268.8\">embedding_1: Embedding</text>\n<polyline fill=\"none\" points=\"471.5,-249.5 471.5,-295.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"500.5\" y=\"-280.3\">input:</text>\n<polyline fill=\"none\" points=\"471.5,-272.5 529.5,-272.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"500.5\" y=\"-257.3\">output:</text>\n<polyline fill=\"none\" points=\"529.5,-249.5 529.5,-295.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"563.5\" y=\"-280.3\">(?, ?)</text>\n<polyline fill=\"none\" points=\"529.5,-272.5 597.5,-272.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"563.5\" y=\"-257.3\">(?, ?, 32)</text>\n</g>\n<!-- 140138997141576&#45;&gt;140140041180552 -->\n<g class=\"edge\" id=\"edge2\">\n<title>140138997141576-&gt;140140041180552</title>\n<path d=\"M449,-332.3799C449,-324.1745 449,-314.7679 449,-305.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"452.5001,-305.784 449,-295.784 445.5001,-305.784 452.5001,-305.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140138997129112 -->\n<g class=\"node\" id=\"node5\">\n<title>140138997129112</title>\n<polygon fill=\"none\" points=\"68.5,-166.5 68.5,-212.5 281.5,-212.5 281.5,-166.5 68.5,-166.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"112\" y=\"-185.8\">lstm: LSTM</text>\n<polyline fill=\"none\" points=\"155.5,-166.5 155.5,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"184.5\" y=\"-197.3\">input:</text>\n<polyline fill=\"none\" points=\"155.5,-189.5 213.5,-189.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"184.5\" y=\"-174.3\">output:</text>\n<polyline fill=\"none\" points=\"213.5,-166.5 213.5,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"247.5\" y=\"-197.3\">(?, ?, 64)</text>\n<polyline fill=\"none\" points=\"213.5,-189.5 281.5,-189.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"247.5\" y=\"-174.3\">(?, 32)</text>\n</g>\n<!-- 140139028904032&#45;&gt;140138997129112 -->\n<g class=\"edge\" id=\"edge3\">\n<title>140139028904032-&gt;140138997129112</title>\n<path d=\"M150.4709,-249.3799C153.9052,-240.9962 157.8532,-231.3584 161.564,-222.2996\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"164.91,-223.3645 165.462,-212.784 158.4324,-220.7109 164.91,-223.3645\" stroke=\"#000000\"/>\n</g>\n<!-- 140140017385768 -->\n<g class=\"node\" id=\"node6\">\n<title>140140017385768</title>\n<polygon fill=\"none\" points=\"317,-166.5 317,-212.5 545,-212.5 545,-166.5 317,-166.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"368\" y=\"-185.8\">lstm_1: LSTM</text>\n<polyline fill=\"none\" points=\"419,-166.5 419,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"448\" y=\"-197.3\">input:</text>\n<polyline fill=\"none\" points=\"419,-189.5 477,-189.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"448\" y=\"-174.3\">output:</text>\n<polyline fill=\"none\" points=\"477,-166.5 477,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"511\" y=\"-197.3\">(?, ?, 32)</text>\n<polyline fill=\"none\" points=\"477,-189.5 545,-189.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"511\" y=\"-174.3\">(?, 16)</text>\n</g>\n<!-- 140140041180552&#45;&gt;140140017385768 -->\n<g class=\"edge\" id=\"edge4\">\n<title>140140041180552-&gt;140140017385768</title>\n<path d=\"M443.986,-249.3799C442.1872,-241.0854 440.1222,-231.5633 438.1759,-222.5889\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"441.5895,-221.815 436.0495,-212.784 434.7485,-223.2987 441.5895,-221.815\" stroke=\"#000000\"/>\n</g>\n<!-- 140138988236528 -->\n<g class=\"node\" id=\"node7\">\n<title>140138988236528</title>\n<polygon fill=\"none\" points=\"131,-83.5 131,-129.5 457,-129.5 457,-83.5 131,-83.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"211\" y=\"-102.8\">concatenate: Concatenate</text>\n<polyline fill=\"none\" points=\"291,-83.5 291,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"320\" y=\"-114.3\">input:</text>\n<polyline fill=\"none\" points=\"291,-106.5 349,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"320\" y=\"-91.3\">output:</text>\n<polyline fill=\"none\" points=\"349,-83.5 349,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"403\" y=\"-114.3\">[(?, 32), (?, 16)]</text>\n<polyline fill=\"none\" points=\"349,-106.5 457,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"403\" y=\"-91.3\">(?, 48)</text>\n</g>\n<!-- 140138997129112&#45;&gt;140138988236528 -->\n<g class=\"edge\" id=\"edge5\">\n<title>140138997129112-&gt;140138988236528</title>\n<path d=\"M208.1481,-166.3799C221.8305,-156.8367 237.8426,-145.6686 252.308,-135.5793\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"254.4171,-138.3755 260.6169,-129.784 250.4126,-132.6341 254.4171,-138.3755\" stroke=\"#000000\"/>\n</g>\n<!-- 140140017385768&#45;&gt;140138988236528 -->\n<g class=\"edge\" id=\"edge6\">\n<title>140140017385768-&gt;140138988236528</title>\n<path d=\"M392.8379,-166.3799C376.7915,-156.6583 357.9617,-145.2505 341.0664,-135.0147\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"342.7991,-131.9722 332.4326,-129.784 339.1719,-137.9592 342.7991,-131.9722\" stroke=\"#000000\"/>\n</g>\n<!-- 140138988236472 -->\n<g class=\"node\" id=\"node8\">\n<title>140138988236472</title>\n<polygon fill=\"none\" points=\"180.5,-.5 180.5,-46.5 407.5,-46.5 407.5,-.5 180.5,-.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"234\" y=\"-19.8\">dense_7: Dense</text>\n<polyline fill=\"none\" points=\"287.5,-.5 287.5,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"316.5\" y=\"-31.3\">input:</text>\n<polyline fill=\"none\" points=\"287.5,-23.5 345.5,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"316.5\" y=\"-8.3\">output:</text>\n<polyline fill=\"none\" points=\"345.5,-.5 345.5,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"376.5\" y=\"-31.3\">(?, 48)</text>\n<polyline fill=\"none\" points=\"345.5,-23.5 407.5,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"376.5\" y=\"-8.3\">(?, 500)</text>\n</g>\n<!-- 140138988236528&#45;&gt;140138988236472 -->\n<g class=\"edge\" id=\"edge7\">\n<title>140138988236528-&gt;140138988236472</title>\n<path d=\"M294,-83.3799C294,-75.1745 294,-65.7679 294,-56.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"297.5001,-56.784 294,-46.784 290.5001,-56.784 297.5001,-56.784\" stroke=\"#000000\"/>\n</g>\n</g>\n</svg>"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-Kk-6Jhptae",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "outputId": "b1593df8-6992-49bf-c985-79d8d2332ddc"
      },
      "source": [
        "import numpy as np\n",
        "num_samples = 1000 \n",
        "max_length = 100\n",
        "import keras\n",
        "\n",
        "# Generates dummy Numpy data\n",
        "text = np.random.randint(1, text_vocabulary_size,size=(num_samples, max_length))\n",
        "question = np.random.randint(1, question_vocabulary_size,size=(num_samples, max_length)) \n",
        "\n",
        "answers = np.random.randint(answer_vocabulary_size, size=(num_samples))\n",
        "answers = keras.utils.to_categorical(answers, answer_vocabulary_size)\n",
        "\n",
        "\n",
        "\n",
        "model.fit([text, question], answers, epochs=10, batch_size=128)\n",
        "\n",
        "#model.fit({'text': text, 'question': question}, answers,epochs=10, batch_size=128)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "8/8 [==============================] - 1s 98ms/step - loss: 6.2145 - acc: 0.0010\n",
            "Epoch 2/10\n",
            "8/8 [==============================] - 1s 96ms/step - loss: 6.1966 - acc: 0.0320\n",
            "Epoch 3/10\n",
            "8/8 [==============================] - 1s 93ms/step - loss: 6.1380 - acc: 0.0060\n",
            "Epoch 4/10\n",
            "8/8 [==============================] - 1s 96ms/step - loss: 6.0601 - acc: 0.0040\n",
            "Epoch 5/10\n",
            "8/8 [==============================] - 1s 97ms/step - loss: 5.9957 - acc: 0.0110\n",
            "Epoch 6/10\n",
            "8/8 [==============================] - 1s 94ms/step - loss: 5.9140 - acc: 0.0140\n",
            "Epoch 7/10\n",
            "8/8 [==============================] - 1s 94ms/step - loss: 5.8203 - acc: 0.0120\n",
            "Epoch 8/10\n",
            "8/8 [==============================] - 1s 94ms/step - loss: 5.7324 - acc: 0.0190\n",
            "Epoch 9/10\n",
            "8/8 [==============================] - 1s 92ms/step - loss: 5.6446 - acc: 0.0300\n",
            "Epoch 10/10\n",
            "8/8 [==============================] - 1s 93ms/step - loss: 5.5642 - acc: 0.0270\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f74a6803c50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EIamnqIUGzoz",
        "colab_type": "text"
      },
      "source": [
        "Listing 7.2 Feeding data to a multi-input model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blZi5X6xGFRk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "outputId": "5832538c-ee7e-4bf9-9fb5-6959e1ad739d"
      },
      "source": [
        "\n",
        "import numpy as np\n",
        "import keras\n",
        "#Generates dummy Numpy data\n",
        "num_samples = 1000\n",
        "max_length = 100\n",
        "text = np.random.randint(1,text_vocabulary_size,size=(num_samples, max_length))\n",
        "question = np.random.randint(1,question_vocabulary_size,size=(num_samples, max_length))\n",
        "answers = np.random.randint(answer_vocabulary_size,size=(num_samples))\n",
        "answers = keras.utils.to_categorical(answers, answer_vocabulary_size)\n",
        "#model.fit([text,question],answers, epochs=10, batch_size=128)\n",
        "model.fit({'text': text, 'question': question}, answers,epochs=10, batch_size=128)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "8/8 [==============================] - 1s 95ms/step - loss: 6.3121 - acc: 0.0020\n",
            "Epoch 2/10\n",
            "8/8 [==============================] - 1s 95ms/step - loss: 6.1645 - acc: 0.0020\n",
            "Epoch 3/10\n",
            "8/8 [==============================] - 1s 97ms/step - loss: 6.0754 - acc: 0.0090\n",
            "Epoch 4/10\n",
            "8/8 [==============================] - 1s 93ms/step - loss: 6.0036 - acc: 0.0110\n",
            "Epoch 5/10\n",
            "8/8 [==============================] - 1s 95ms/step - loss: 5.9171 - acc: 0.0140\n",
            "Epoch 6/10\n",
            "8/8 [==============================] - 1s 94ms/step - loss: 5.8249 - acc: 0.0170\n",
            "Epoch 7/10\n",
            "8/8 [==============================] - 1s 93ms/step - loss: 5.7309 - acc: 0.0250\n",
            "Epoch 8/10\n",
            "8/8 [==============================] - 1s 100ms/step - loss: 5.6618 - acc: 0.0250\n",
            "Epoch 9/10\n",
            "8/8 [==============================] - 1s 95ms/step - loss: 5.5681 - acc: 0.0290\n",
            "Epoch 10/10\n",
            "8/8 [==============================] - 1s 95ms/step - loss: 5.4960 - acc: 0.0330\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f74a587f198>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FiqJwrTCqXhH",
        "colab_type": "text"
      },
      "source": [
        "Listing 7.3 Functional API implementation of a three-output model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imxhsmX5TZtZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "faf3bee5-9e13-4a76-c038-9e79ad57f53f"
      },
      "source": [
        "from keras import layers\n",
        "from keras import Input \n",
        "from keras.models import Model \n",
        "\n",
        "vocabulary_size = 50000 \n",
        "num_income_groups = 10 \n",
        "\n",
        "posts_input = Input(shape=(None,), dtype='int32', name='posts')\n",
        "\n",
        "#embedded_posts = layers.Embedding(256, vocabulary_size)(posts_input) \n",
        "embedded_posts = layers.Embedding(vocabulary_size,256)(posts_input)\n",
        "\n",
        "x = layers.Conv1D(128, 5, activation='relu', padding='same')(embedded_posts)\n",
        "x = layers.MaxPooling1D(5)(x)\n",
        "x = layers.Conv1D(256, 5, activation='relu', padding='same')(x)\n",
        "x = layers.Conv1D(256, 5, activation='relu', padding='same')(x)\n",
        "x = layers.MaxPooling1D(5)(x)\n",
        "x = layers.Conv1D(256, 5, activation='relu', padding='same')(x)\n",
        "x = layers.Conv1D(256, 5, activation='relu', padding='same')(x) \n",
        "x = layers.GlobalMaxPooling1D()(x)\n",
        "x = layers.Dense(128, activation='relu')(x) \n",
        "\n",
        "# Note that the output layers are given names.\n",
        "\n",
        "age_prediction = layers.Dense(1, name='age')(x)\n",
        "\n",
        "income_prediction = layers.Dense(num_income_groups, activation='softmax',name='income')(x)\n",
        "\n",
        "gender_prediction = layers.Dense(1, activation='sigmoid', name='gender')(x)\n",
        "\n",
        "model = Model(posts_input,[age_prediction, income_prediction, gender_prediction])\n",
        "\n",
        "print(\"Model is ready!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model is ready!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLTQgiVCUjd_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 622
        },
        "outputId": "2ef98673-539d-45da-e122-d577a8e95abb"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_5\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "posts (InputLayer)              [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_2 (Embedding)         (None, None, 256)    12800000    posts[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv1d (Conv1D)                 (None, None, 128)    163968      embedding_2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D)    (None, None, 128)    0           conv1d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_1 (Conv1D)               (None, None, 256)    164096      max_pooling1d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_2 (Conv1D)               (None, None, 256)    327936      conv1d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1D)  (None, None, 256)    0           conv1d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_3 (Conv1D)               (None, None, 256)    327936      max_pooling1d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_4 (Conv1D)               (None, None, 256)    327936      conv1d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d (GlobalMax (None, 256)          0           conv1d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_8 (Dense)                 (None, 128)          32896       global_max_pooling1d[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "age (Dense)                     (None, 1)            129         dense_8[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "income (Dense)                  (None, 10)           1290        dense_8[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "gender (Dense)                  (None, 1)            129         dense_8[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 14,146,316\n",
            "Trainable params: 14,146,316\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwmAqvBFYTxC",
        "colab_type": "text"
      },
      "source": [
        "### ***Listing 7.4 Compilation options of a multi-output model: multiple losses***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jiAaZnluT_xh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###Compilation options of a multi-output model: multiple losses###\n",
        "model.compile(optimizer='rmsprop',loss=['mse', 'categorical_crossentropy', 'binary_crossentropy'])\n",
        "##Equivalent (possible only if you give names to the output layers) ##\n",
        "#model.compile(optimizer='rmsprop',loss={'age': 'mse','income': 'categorical_crossentropy','gender': 'binary_crossentropy'})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9y8-AiYUHHo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "outputId": "8715869a-faa1-4201-8e72-19c7091f55b0"
      },
      "source": [
        "import numpy as np \n",
        "import keras\n",
        "\n",
        "\n",
        "num_samples = 1000 \n",
        "max_length = 100 \n",
        "\n",
        "posts = np.random.randint(1, vocabulary_size, size=(num_samples, max_length))\n",
        "\n",
        "\n",
        "age_targets = np.random.randint(0, 100, size=(num_samples,1))\n",
        "\n",
        "income_targets = np.random.randint(1, num_income_groups, size=(num_samples,1))\n",
        "income_targets = keras.utils.to_categorical(income_targets,num_income_groups)\n",
        "\n",
        "gender_targets = np.random.randint(0, 2, size=(num_samples,1))\n",
        "\n",
        "\n",
        "# age_targets, income_targets, and gender_targets are assumed to be Numpy arrays.\n",
        "\n",
        "model.fit(posts, [age_targets, income_targets, gender_targets], epochs=10, batch_size=64)\n",
        "\n",
        "# Equivalent (possible only if you give names to the output layers)\n",
        "\n",
        "#model.fit(posts, {'age': age_targets,'income': income_targets,'gender': gender_targets},epochs=10, batch_size=64)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "16/16 [==============================] - 7s 437ms/step - loss: 1634.6246 - age_loss: 1628.7164 - income_loss: 3.5986 - gender_loss: 2.3097\n",
            "Epoch 2/10\n",
            "16/16 [==============================] - 7s 438ms/step - loss: 829.2762 - age_loss: 826.1501 - income_loss: 2.3640 - gender_loss: 0.7620\n",
            "Epoch 3/10\n",
            "16/16 [==============================] - 7s 440ms/step - loss: 803.1984 - age_loss: 800.2040 - income_loss: 2.2862 - gender_loss: 0.7081\n",
            "Epoch 4/10\n",
            "16/16 [==============================] - 7s 435ms/step - loss: 342.1697 - age_loss: 339.1999 - income_loss: 2.2574 - gender_loss: 0.7124\n",
            "Epoch 5/10\n",
            "16/16 [==============================] - 7s 437ms/step - loss: 387.3622 - age_loss: 384.4022 - income_loss: 2.2606 - gender_loss: 0.6994\n",
            "Epoch 6/10\n",
            "16/16 [==============================] - 7s 429ms/step - loss: 512.1121 - age_loss: 509.1537 - income_loss: 2.2381 - gender_loss: 0.7202\n",
            "Epoch 7/10\n",
            "16/16 [==============================] - 7s 433ms/step - loss: 287.6184 - age_loss: 284.6369 - income_loss: 2.2618 - gender_loss: 0.7197\n",
            "Epoch 8/10\n",
            "16/16 [==============================] - 7s 435ms/step - loss: 384.3564 - age_loss: 381.3916 - income_loss: 2.2569 - gender_loss: 0.7079\n",
            "Epoch 9/10\n",
            "16/16 [==============================] - 7s 436ms/step - loss: 250.7682 - age_loss: 247.7926 - income_loss: 2.2674 - gender_loss: 0.7083\n",
            "Epoch 10/10\n",
            "16/16 [==============================] - 7s 435ms/step - loss: 313.8385 - age_loss: 310.8400 - income_loss: 2.2822 - gender_loss: 0.7162\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f74a8f346a0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ox4SCUF9rUfh",
        "colab_type": "text"
      },
      "source": [
        "Listing 7.5 Compilation options of a multi-output model: loss weighting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXZmXfgvq9x3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#### Compilation options of a multi-output model: loss weighting####\n",
        "model.compile(optimizer='rmsprop',\n",
        "loss=['mse', 'categorical_crossentropy', 'binary_crossentropy'],loss_weights=[0.25, 1., 10.])\n",
        "\n",
        "##Equivalent (possible only if you give names to the output layers) ##\n",
        "#model.compile(optimizer='rmsprop',loss={'age': 'mse','income': 'categorical_crossentropy','gender': 'binary_crossentropy'},\n",
        "#loss_weights={'age': 0.25,'income': 1.,'gender': 10.})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ij9pWdMWZiqP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "outputId": "2e609012-a8e5-4ab2-be45-3ca7eca1f714"
      },
      "source": [
        "import numpy as np \n",
        "import keras\n",
        "\n",
        "\n",
        "num_samples = 1000 \n",
        "max_length = 100 \n",
        "\n",
        "posts = np.random.randint(1, vocabulary_size, size=(num_samples, max_length))\n",
        "\n",
        "\n",
        "age_targets = np.random.randint(0, 100, size=(num_samples,1))\n",
        "\n",
        "income_targets = np.random.randint(1, num_income_groups, size=(num_samples,1))\n",
        "income_targets = keras.utils.to_categorical(income_targets,num_income_groups)\n",
        "\n",
        "gender_targets = np.random.randint(0, 2, size=(num_samples,1))\n",
        "\n",
        "\n",
        "# age_targets, income_targets, and gender_targets are assumed to be Numpy arrays.\n",
        "\n",
        "model.fit(posts, [age_targets, income_targets, gender_targets], epochs=10, batch_size=64)\n",
        "\n",
        "# Equivalent (possible only if you give names to the output layers)\n",
        "\n",
        "#model.fit(posts, {'age': age_targets,'income': income_targets,'gender': gender_targets},epochs=10, batch_size=64)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "16/16 [==============================] - 7s 440ms/step - loss: 451.7021 - age_loss: 1768.5016 - income_loss: 2.3710 - gender_loss: 0.7206\n",
            "Epoch 2/10\n",
            "16/16 [==============================] - 7s 437ms/step - loss: 118.0697 - age_loss: 429.9289 - income_loss: 2.2774 - gender_loss: 0.8310\n",
            "Epoch 3/10\n",
            "16/16 [==============================] - 7s 439ms/step - loss: 80.3882 - age_loss: 274.2931 - income_loss: 2.3295 - gender_loss: 0.9485\n",
            "Epoch 4/10\n",
            "16/16 [==============================] - 7s 439ms/step - loss: 81.1257 - age_loss: 280.7173 - income_loss: 2.3010 - gender_loss: 0.8645\n",
            "Epoch 5/10\n",
            "16/16 [==============================] - 7s 440ms/step - loss: 89.1738 - age_loss: 304.0735 - income_loss: 2.3641 - gender_loss: 1.0791\n",
            "Epoch 6/10\n",
            "16/16 [==============================] - 7s 439ms/step - loss: 65.6730 - age_loss: 216.1313 - income_loss: 2.3205 - gender_loss: 0.9320\n",
            "Epoch 7/10\n",
            "16/16 [==============================] - 7s 434ms/step - loss: 68.0640 - age_loss: 229.2402 - income_loss: 2.3228 - gender_loss: 0.8431\n",
            "Epoch 8/10\n",
            "16/16 [==============================] - 7s 445ms/step - loss: 68.1122 - age_loss: 226.8410 - income_loss: 2.3324 - gender_loss: 0.9070\n",
            "Epoch 9/10\n",
            "16/16 [==============================] - 7s 437ms/step - loss: 68.2212 - age_loss: 225.7558 - income_loss: 2.2775 - gender_loss: 0.9505\n",
            "Epoch 10/10\n",
            "16/16 [==============================] - 7s 434ms/step - loss: 62.2160 - age_loss: 204.8036 - income_loss: 2.2769 - gender_loss: 0.8738\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f74a8bff0f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UoemW4jjsWXQ",
        "colab_type": "text"
      },
      "source": [
        "Listing 7.6 Feeding data to a multi-output model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PY-wOFrirrbM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "outputId": "aabccf03-1414-41c2-898b-d1ab653d60f9"
      },
      "source": [
        "#### Feeding data to a multi-output model ###\n",
        "model.fit(posts, [age_targets, income_targets, gender_targets],\n",
        "epochs=10, batch_size=64)\n",
        "##Equivalent (possible only if you give names to the output layers) ##\n",
        "#model.fit(posts_input, {'age': age_targets,'income': income_targets,'gender': gender_targets},epochs=10, batch_size=64)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "16/16 [==============================] - 7s 436ms/step - loss: 71.6516 - age_loss: 243.0056 - income_loss: 2.2762 - gender_loss: 0.8624\n",
            "Epoch 2/10\n",
            "16/16 [==============================] - 7s 434ms/step - loss: 43.5968 - age_loss: 128.3760 - income_loss: 2.2975 - gender_loss: 0.9205\n",
            "Epoch 3/10\n",
            "16/16 [==============================] - 7s 436ms/step - loss: 63.4154 - age_loss: 207.0587 - income_loss: 2.3022 - gender_loss: 0.9348\n",
            "Epoch 4/10\n",
            "16/16 [==============================] - 7s 437ms/step - loss: 51.8989 - age_loss: 161.8346 - income_loss: 2.3089 - gender_loss: 0.9131\n",
            "Epoch 5/10\n",
            "16/16 [==============================] - 7s 440ms/step - loss: 57.1714 - age_loss: 187.0663 - income_loss: 2.2714 - gender_loss: 0.8133\n",
            "Epoch 6/10\n",
            "16/16 [==============================] - 7s 435ms/step - loss: 56.9107 - age_loss: 185.6816 - income_loss: 2.2903 - gender_loss: 0.8200\n",
            "Epoch 7/10\n",
            "16/16 [==============================] - 7s 433ms/step - loss: 49.2582 - age_loss: 154.8842 - income_loss: 2.2794 - gender_loss: 0.8258\n",
            "Epoch 8/10\n",
            "16/16 [==============================] - 7s 438ms/step - loss: 44.7036 - age_loss: 139.6138 - income_loss: 2.2853 - gender_loss: 0.7515\n",
            "Epoch 9/10\n",
            "16/16 [==============================] - 7s 434ms/step - loss: 47.4781 - age_loss: 147.8983 - income_loss: 2.2552 - gender_loss: 0.8248\n",
            "Epoch 10/10\n",
            "16/16 [==============================] - 7s 436ms/step - loss: 47.4892 - age_loss: 150.5703 - income_loss: 2.2653 - gender_loss: 0.7581\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f74a88d0860>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EfRJURbDaFje",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "outputId": "a48dcd2c-2935-4899-b046-c68ec2622c49"
      },
      "source": [
        "import numpy as np \n",
        "import keras\n",
        "\n",
        "\n",
        "num_samples = 1000 \n",
        "max_length = 100 \n",
        "\n",
        "posts = np.random.randint(1, vocabulary_size, size=(num_samples, max_length))\n",
        "\n",
        "\n",
        "age_targets = np.random.randint(0, 100, size=(num_samples,1))\n",
        "\n",
        "\n",
        "income_targets = np.random.randint(1, num_income_groups, size=(num_samples,1))\n",
        "income_targets = keras.utils.to_categorical(income_targets,num_income_groups)\n",
        "\n",
        "\n",
        "gender_targets = np.random.randint(0, 2, size=(num_samples,1))\n",
        "\n",
        "\n",
        "# age_targets, income_targets, and gender_targets are assumed to be Numpy arrays.\n",
        "\n",
        "model.fit(posts, [age_targets, income_targets, gender_targets], epochs=10, batch_size=64)\n",
        "\n",
        "# Equivalent (possible only if you give names to the output layers)\n",
        "\n",
        "#model.fit(posts, {'age': age_targets,'income': income_targets,'gender': gender_targets},epochs=10, batch_size=64)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "16/16 [==============================] - 7s 435ms/step - loss: 214.0938 - age_loss: 815.8174 - income_loss: 2.2641 - gender_loss: 0.7875\n",
            "Epoch 2/10\n",
            "16/16 [==============================] - 7s 434ms/step - loss: 121.9849 - age_loss: 448.2116 - income_loss: 2.2556 - gender_loss: 0.7676\n",
            "Epoch 3/10\n",
            "16/16 [==============================] - 7s 425ms/step - loss: 58.6829 - age_loss: 191.9621 - income_loss: 2.2953 - gender_loss: 0.8397\n",
            "Epoch 4/10\n",
            "16/16 [==============================] - 7s 427ms/step - loss: 53.1492 - age_loss: 170.8663 - income_loss: 2.2616 - gender_loss: 0.8171\n",
            "Epoch 5/10\n",
            "16/16 [==============================] - 7s 431ms/step - loss: 49.0704 - age_loss: 154.3206 - income_loss: 2.2756 - gender_loss: 0.8215\n",
            "Epoch 6/10\n",
            "16/16 [==============================] - 7s 431ms/step - loss: 50.8198 - age_loss: 162.2258 - income_loss: 2.2888 - gender_loss: 0.7975\n",
            "Epoch 7/10\n",
            "16/16 [==============================] - 7s 435ms/step - loss: 44.7658 - age_loss: 140.8799 - income_loss: 2.2378 - gender_loss: 0.7308\n",
            "Epoch 8/10\n",
            "16/16 [==============================] - 7s 437ms/step - loss: 44.0076 - age_loss: 138.4575 - income_loss: 2.2704 - gender_loss: 0.7123\n",
            "Epoch 9/10\n",
            "16/16 [==============================] - 7s 432ms/step - loss: 44.1584 - age_loss: 137.2289 - income_loss: 2.2647 - gender_loss: 0.7586\n",
            "Epoch 10/10\n",
            "16/16 [==============================] - 7s 431ms/step - loss: 37.2124 - age_loss: 111.6553 - income_loss: 2.2535 - gender_loss: 0.7045\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f74a88852e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "INm8TAb5jrm1",
        "colab_type": "text"
      },
      "source": [
        "INCEPTION MODULES\n",
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q4zf88RDtZ9h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "outputId": "91d88c15-179f-4bef-d20d-e581e8b03fc0"
      },
      "source": [
        "from keras import layers\n",
        "from keras.layers import Input\n",
        "\n",
        "# This example assumes the existence of a 4D input tensor x:\n",
        "# This returns a typical image tensor like those of MNIST dataset\n",
        "\n",
        "x = Input(shape=(28, 28, 1), dtype='float32', name='images')\n",
        "print(\"x.shape:\",x.shape)\n",
        "\n",
        "branch_a = layers.Conv2D(128, 1,activation='relu', strides=2)(x)\n",
        "branch_b = layers.Conv2D(128, 1, activation='relu')(x)\n",
        "branch_b = layers.Conv2D(128, 3, activation='relu', strides=2)(branch_b)\n",
        "branch_c = layers.AveragePooling2D(3, strides=2)(x)\n",
        "branch_c = layers.Conv2D(128, 3, activation='relu')(branch_c)\n",
        "branch_d = layers.Conv2D(128, 1, activation='relu')(x)\n",
        "branch_d = layers.Conv2D(128, 3, activation='relu')(branch_d)\n",
        "branch_d = layers.Conv2D(128, 3, activation='relu', strides=2)(branch_d)\n",
        "output = layers.concatenate([branch_a, branch_b, branch_c, branch_d], axis=-1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-3e3d65c93037>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#print(\"x.shape:\",x.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mbranch_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mbranch_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mbranch_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbranch_b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'x' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTYnZUnpjvFM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "71813406-9d09-4609-c5d0-69177fff559b"
      },
      "source": [
        "import keras\n",
        "from keras import layers \n",
        "from keras.layers import Input\n",
        "\n",
        "\n",
        "x = Input(shape=(28, 28, 1), dtype='float32', name='images')\n",
        "print(\"x.shape:\",x.shape)\n",
        "\n",
        "\n",
        "branch_a = layers.Conv2D(128, 1, padding='same', activation='relu', strides=2)(x)\n",
        "\n",
        "branch_b = layers.Conv2D(128, 1, padding='same', activation='relu')(x)\n",
        "branch_b = layers.Conv2D(128, 3, padding='same', activation='relu', strides=2)(branch_b)\n",
        "\n",
        "branch_c = layers.AveragePooling2D(3,  padding='same', strides=2)(x)\n",
        "branch_c = layers.Conv2D(128, 3, padding='same', activation='relu')(branch_c)\n",
        "\n",
        "branch_d = layers.Conv2D(128, 1, padding='same', activation='relu')(x) \n",
        "branch_d = layers.Conv2D(128, 3, padding='same', activation='relu')(branch_d)\n",
        "branch_d = layers.Conv2D(128, 3, padding='same', activation='relu', strides=2)(branch_d)\n",
        "\n",
        "output = layers.concatenate([branch_a, branch_b, branch_c, branch_d], axis=-1)\n",
        "\n",
        "output = layers.Flatten()(output)\n",
        "output = layers.Dense(512, activation='relu')(output)\n",
        "predictions = layers.Dense(10, activation='softmax')(output)\n",
        "\n",
        "model = keras.models.Model(inputs=x, outputs=predictions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x.shape: (None, 28, 28, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTLbPUstZsIf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}